{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing logistic matrix factorization code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_mf import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading a csv into pandas\n",
    "train = pd.read_csv(\"train_books_ratings.csv\")\n",
    "valid = pd.read_csv(\"valid_books_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2E2F4MLVYDGEQ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>0</td>\n",
       "      <td>1393286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A386A9WE42M4PG</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>0</td>\n",
       "      <td>1371772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1OGQA984MTKBH</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>0</td>\n",
       "      <td>1372118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VVBHGM8DFIZ4</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>0</td>\n",
       "      <td>1387152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD6E4Y092Y4KP</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>0</td>\n",
       "      <td>1392336000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0  A2E2F4MLVYDGEQ  000100039X       0  1393286400\n",
       "1  A386A9WE42M4PG  000100039X       0  1371772800\n",
       "2  A1OGQA984MTKBH  000100039X       0  1372118400\n",
       "3  A1VVBHGM8DFIZ4  000100039X       0  1387152000\n",
       "4   AD6E4Y092Y4KP  000100039X       0  1392336000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = encode_data(train, train=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = encode_data(valid, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446156</th>\n",
       "      <td>710749</td>\n",
       "      <td>45868</td>\n",
       "      <td>1</td>\n",
       "      <td>1333584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446159</th>\n",
       "      <td>590160</td>\n",
       "      <td>45082</td>\n",
       "      <td>1</td>\n",
       "      <td>1335139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446161</th>\n",
       "      <td>910780</td>\n",
       "      <td>62851</td>\n",
       "      <td>1</td>\n",
       "      <td>1057881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446163</th>\n",
       "      <td>764823</td>\n",
       "      <td>32666</td>\n",
       "      <td>1</td>\n",
       "      <td>1241308800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446166</th>\n",
       "      <td>345398</td>\n",
       "      <td>325600</td>\n",
       "      <td>1</td>\n",
       "      <td>1378598400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user    item  rating   timestamp\n",
       "446156  710749   45868       1  1333584000\n",
       "446159  590160   45082       1  1335139200\n",
       "446161  910780   62851       1  1057881600\n",
       "446163  764823   32666       1  1241308800\n",
       "446166  345398  325600       1  1378598400"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312778 659279\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train_df.user.unique())\n",
    "num_items = len(train_df.item.unique())\n",
    "print(num_users, num_items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.LongTensor(train_df.user.values[:5]).long()\n",
    "v = torch.LongTensor(train_df.item.values[:5]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         ...,\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519]],\n",
       "\n",
       "        [[0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         ...,\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519]],\n",
       "\n",
       "        [[0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         ...,\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519]],\n",
       "\n",
       "        [[0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         ...,\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519]],\n",
       "\n",
       "        [[0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         ...,\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519],\n",
       "         [0.0513, 0.0604, 0.0599, 0.0529, 0.0519]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m MF(num_users, num_items, emb_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/Downloads/Prework/ad_ml_hw2/logistic_mf.py:34\u001b[0m, in \u001b[0;36mMF.__init__\u001b[0;34m(self, num_users, num_items, emb_size, seed)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_users, num_items, emb_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m23\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[39msuper\u001b[39;49m(MF, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m     36\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_emb \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(num_users, emb_size)\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = MF(num_users, num_items, emb_size=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1278144011299600 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training(model, train_df, valid_df, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, wd\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m)\n",
      "File \u001b[0;32m~/Downloads/Prework/ad_ml_hw2/logistic_mf.py:93\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, train_df, valid_df, epochs, lr, wd)\u001b[0m\n\u001b[1;32m     91\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mwd)\n\u001b[1;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> 93\u001b[0m     train_loss \u001b[39m=\u001b[39m train_one_epoch(model, train_df, optimizer)\n\u001b[1;32m     94\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m valid_metrics(model, valid_df) \n\u001b[1;32m     95\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain loss \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m valid loss \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m valid acc \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (train_loss, valid_loss, valid_acc))\n",
      "File \u001b[0;32m~/Downloads/Prework/ad_ml_hw2/logistic_mf.py:63\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_df, optimizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m items \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(train_df\u001b[39m.\u001b[39mitem\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m     61\u001b[0m ratings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(train_df\u001b[39m.\u001b[39mrating\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m---> 63\u001b[0m y_hat \u001b[39m=\u001b[39m model(users, items)\n\u001b[1;32m     64\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(y_hat, ratings)\n\u001b[1;32m     65\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/Prework/ad_ml_hw2/logistic_mf.py:53\u001b[0m, in \u001b[0;36mMF.forward\u001b[0;34m(self, u, v)\u001b[0m\n\u001b[1;32m     51\u001b[0m v_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_bias(v\u001b[39m.\u001b[39mlong())\n\u001b[1;32m     52\u001b[0m product \u001b[39m=\u001b[39m (u \u001b[39m*\u001b[39m v)\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[39mreturn\u001b[39;00m product \u001b[39m+\u001b[39;49m u_bias \u001b[39m+\u001b[39m v_bias\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1278144011299600 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "training(model, train_df, valid_df, epochs=10, lr=0.1, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training(model, train_df, valid_df, epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, wd\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m)\n",
      "File \u001b[0;32m~/Downloads/Prework/logistic_mf.py:93\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, train_df, valid_df, epochs, lr, wd)\u001b[0m\n\u001b[1;32m     91\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mwd)\n\u001b[1;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> 93\u001b[0m     train_loss \u001b[39m=\u001b[39m train_one_epoch(model, train_df, optimizer)\n\u001b[1;32m     94\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m valid_metrics(model, valid_df) \n\u001b[1;32m     95\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain loss \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m valid loss \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m valid acc \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (train_loss, valid_loss, valid_acc))\n",
      "File \u001b[0;32m~/Downloads/Prework/logistic_mf.py:63\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_df, optimizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m items \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(train_df\u001b[39m.\u001b[39mitem\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m     61\u001b[0m ratings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(train_df\u001b[39m.\u001b[39mrating\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m---> 63\u001b[0m y_hat \u001b[39m=\u001b[39m model(users, items)\n\u001b[1;32m     64\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(y_hat, ratings)\n\u001b[1;32m     65\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/Prework/logistic_mf.py:50\u001b[0m, in \u001b[0;36mMF.forward\u001b[0;34m(self, u, v)\u001b[0m\n\u001b[1;32m     48\u001b[0m u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_emb(u)\n\u001b[1;32m     49\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_emb(v)\n\u001b[0;32m---> 50\u001b[0m u_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_bias(u)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     51\u001b[0m v_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_bias(v)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m (u \u001b[39m*\u001b[39m v)\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m u_bias \u001b[39m+\u001b[39m v_bias\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "training(model, train_df, valid_df, epochs=15, lr=0.01, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_and_data():\n",
    "    train = pd.read_csv(\"~/Downloads/prework/train_books_ratings_tiny.csv\")\n",
    "    valid = pd.read_csv(\"~/Downloads/prework/valid_books_ratings_tiny.csv\")\n",
    "    train_df = encode_data(train, train=None)\n",
    "    valid_df = encode_data(valid, train=train)\n",
    "    num_users = len(train.user.unique())\n",
    "    num_items = len(train.item.unique())\n",
    "    model = MF(num_users, num_items)\n",
    "    return model, train_df, valid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m u \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(df\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m      3\u001b[0m v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(df\u001b[39m.\u001b[39mitem\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m----> 4\u001b[0m y_hat \u001b[39m=\u001b[39m model(u, v)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/Prework/logistic_mf.py:50\u001b[0m, in \u001b[0;36mMF.forward\u001b[0;34m(self, u, v)\u001b[0m\n\u001b[1;32m     48\u001b[0m u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_emb(u)\n\u001b[1;32m     49\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_emb(v)\n\u001b[0;32m---> 50\u001b[0m u_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_bias(u)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     51\u001b[0m v_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_bias(v)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m (u \u001b[39m*\u001b[39m v)\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m u_bias \u001b[39m+\u001b[39m v_bias\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "model, df, _  = init_model_and_data() \n",
    "u = torch.LongTensor(df.user.values)\n",
    "v = torch.LongTensor(df.item.values)\n",
    "y_hat = model(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please see the last part for homework answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking are images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0][:4][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = images.view(-1, 28*28) #.cuda()\n",
    "            # Fill in here please\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total += batch\n",
    "            sum_loss += batch * loss.item()\n",
    "\n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)  #.cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).sum().item()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with L2 regularization\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules) #.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 75.9953\n",
      "Epoch [1/10], Valid Accuracy: 10.1400, Valid Loss: 2.3983\n",
      "Epoch [2/10], Loss: 3.3413\n",
      "Epoch [2/10], Valid Accuracy: 8.9700, Valid Loss: 2.4071\n",
      "Epoch [3/10], Loss: 2.5148\n",
      "Epoch [3/10], Valid Accuracy: 9.7900, Valid Loss: 2.4783\n",
      "Epoch [4/10], Loss: 2.4095\n",
      "Epoch [4/10], Valid Accuracy: 10.3300, Valid Loss: 2.3555\n",
      "Epoch [5/10], Loss: 2.4041\n",
      "Epoch [5/10], Valid Accuracy: 11.4000, Valid Loss: 2.3676\n",
      "Epoch [6/10], Loss: 2.4057\n",
      "Epoch [6/10], Valid Accuracy: 10.1500, Valid Loss: 2.4834\n",
      "Epoch [7/10], Loss: 2.4144\n",
      "Epoch [7/10], Valid Accuracy: 9.8700, Valid Loss: 2.5034\n",
      "Epoch [8/10], Loss: 2.4064\n",
      "Epoch [8/10], Valid Accuracy: 9.7900, Valid Loss: 2.3734\n",
      "Epoch [9/10], Loss: 2.4063\n",
      "Epoch [9/10], Valid Accuracy: 11.4000, Valid Loss: 2.4149\n",
      "Epoch [10/10], Loss: 2.4094\n",
      "Epoch [10/10], Valid Accuracy: 8.9700, Valid Loss: 2.4437\n",
      "Epoch [1/10], Loss: 2.7754\n",
      "Epoch [1/10], Valid Accuracy: 14.3800, Valid Loss: 2.2607\n",
      "Epoch [2/10], Loss: 2.3291\n",
      "Epoch [2/10], Valid Accuracy: 10.1000, Valid Loss: 2.3153\n",
      "Epoch [3/10], Loss: 2.3028\n",
      "Epoch [3/10], Valid Accuracy: 12.6500, Valid Loss: 2.2810\n",
      "Epoch [4/10], Loss: 2.3198\n",
      "Epoch [4/10], Valid Accuracy: 10.3100, Valid Loss: 2.3245\n",
      "Epoch [5/10], Loss: 2.3138\n",
      "Epoch [5/10], Valid Accuracy: 9.8100, Valid Loss: 2.3217\n",
      "Epoch [6/10], Loss: 2.3136\n",
      "Epoch [6/10], Valid Accuracy: 10.2900, Valid Loss: 2.3125\n",
      "Epoch [7/10], Loss: 2.3144\n",
      "Epoch [7/10], Valid Accuracy: 11.3600, Valid Loss: 2.3220\n",
      "Epoch [8/10], Loss: 2.3139\n",
      "Epoch [8/10], Valid Accuracy: 11.3600, Valid Loss: 2.3140\n",
      "Epoch [9/10], Loss: 2.3145\n",
      "Epoch [9/10], Valid Accuracy: 10.1100, Valid Loss: 2.3236\n",
      "Epoch [10/10], Loss: 2.3143\n",
      "Epoch [10/10], Valid Accuracy: 10.2900, Valid Loss: 2.3153\n",
      "Epoch [1/10], Loss: 0.3370\n",
      "Epoch [1/10], Valid Accuracy: 93.7500, Valid Loss: 0.2471\n",
      "Epoch [2/10], Loss: 0.2740\n",
      "Epoch [2/10], Valid Accuracy: 92.6300, Valid Loss: 0.2705\n",
      "Epoch [3/10], Loss: 0.2561\n",
      "Epoch [3/10], Valid Accuracy: 92.7600, Valid Loss: 0.2772\n",
      "Epoch [4/10], Loss: 0.2540\n",
      "Epoch [4/10], Valid Accuracy: 93.9000, Valid Loss: 0.2499\n",
      "Epoch [5/10], Loss: 0.2411\n",
      "Epoch [5/10], Valid Accuracy: 93.5700, Valid Loss: 0.3059\n",
      "Epoch [6/10], Loss: 0.2423\n",
      "Epoch [6/10], Valid Accuracy: 92.8600, Valid Loss: 0.2823\n",
      "Epoch [7/10], Loss: 0.2292\n",
      "Epoch [7/10], Valid Accuracy: 92.9600, Valid Loss: 0.3245\n",
      "Epoch [8/10], Loss: 0.2268\n",
      "Epoch [8/10], Valid Accuracy: 93.8600, Valid Loss: 0.2784\n",
      "Epoch [9/10], Loss: 0.2242\n",
      "Epoch [9/10], Valid Accuracy: 93.9500, Valid Loss: 0.2794\n",
      "Epoch [10/10], Loss: 0.2217\n",
      "Epoch [10/10], Valid Accuracy: 93.5000, Valid Loss: 0.2859\n",
      "Epoch [1/10], Loss: 0.2001\n",
      "Epoch [1/10], Valid Accuracy: 96.7500, Valid Loss: 0.1076\n",
      "Epoch [2/10], Loss: 0.0880\n",
      "Epoch [2/10], Valid Accuracy: 97.1200, Valid Loss: 0.0924\n",
      "Epoch [3/10], Loss: 0.0632\n",
      "Epoch [3/10], Valid Accuracy: 97.1200, Valid Loss: 0.1025\n",
      "Epoch [4/10], Loss: 0.0474\n",
      "Epoch [4/10], Valid Accuracy: 97.5400, Valid Loss: 0.0855\n",
      "Epoch [5/10], Loss: 0.0397\n",
      "Epoch [5/10], Valid Accuracy: 97.8800, Valid Loss: 0.0799\n",
      "Epoch [6/10], Loss: 0.0332\n",
      "Epoch [6/10], Valid Accuracy: 98.1900, Valid Loss: 0.0748\n",
      "Epoch [7/10], Loss: 0.0281\n",
      "Epoch [7/10], Valid Accuracy: 97.9000, Valid Loss: 0.0871\n",
      "Epoch [8/10], Loss: 0.0233\n",
      "Epoch [8/10], Valid Accuracy: 97.8100, Valid Loss: 0.0946\n",
      "Epoch [9/10], Loss: 0.0226\n",
      "Epoch [9/10], Valid Accuracy: 97.9000, Valid Loss: 0.0884\n",
      "Epoch [10/10], Loss: 0.0230\n",
      "Epoch [10/10], Valid Accuracy: 97.6700, Valid Loss: 0.1050\n",
      "Epoch [1/10], Loss: 0.4077\n",
      "Epoch [1/10], Valid Accuracy: 93.5800, Valid Loss: 0.2250\n",
      "Epoch [2/10], Loss: 0.1965\n",
      "Epoch [2/10], Valid Accuracy: 95.3900, Valid Loss: 0.1633\n",
      "Epoch [3/10], Loss: 0.1443\n",
      "Epoch [3/10], Valid Accuracy: 96.2900, Valid Loss: 0.1269\n",
      "Epoch [4/10], Loss: 0.1133\n",
      "Epoch [4/10], Valid Accuracy: 96.9300, Valid Loss: 0.1063\n",
      "Epoch [5/10], Loss: 0.0917\n",
      "Epoch [5/10], Valid Accuracy: 97.2200, Valid Loss: 0.0957\n",
      "Epoch [6/10], Loss: 0.0766\n",
      "Epoch [6/10], Valid Accuracy: 97.5900, Valid Loss: 0.0849\n",
      "Epoch [7/10], Loss: 0.0646\n",
      "Epoch [7/10], Valid Accuracy: 97.5500, Valid Loss: 0.0793\n",
      "Epoch [8/10], Loss: 0.0551\n",
      "Epoch [8/10], Valid Accuracy: 97.6600, Valid Loss: 0.0749\n",
      "Epoch [9/10], Loss: 0.0477\n",
      "Epoch [9/10], Valid Accuracy: 97.9500, Valid Loss: 0.0693\n",
      "Epoch [10/10], Loss: 0.0410\n",
      "Epoch [10/10], Valid Accuracy: 98.0200, Valid Loss: 0.0673\n",
      "Epoch [1/10], Loss: 1.1233\n",
      "Epoch [1/10], Valid Accuracy: 87.3100, Valid Loss: 0.5787\n",
      "Epoch [2/10], Loss: 0.4853\n",
      "Epoch [2/10], Valid Accuracy: 90.0100, Valid Loss: 0.3959\n",
      "Epoch [3/10], Loss: 0.3775\n",
      "Epoch [3/10], Valid Accuracy: 91.1600, Valid Loss: 0.3344\n",
      "Epoch [4/10], Loss: 0.3317\n",
      "Epoch [4/10], Valid Accuracy: 91.6700, Valid Loss: 0.3032\n",
      "Epoch [5/10], Loss: 0.3038\n",
      "Epoch [5/10], Valid Accuracy: 92.2400, Valid Loss: 0.2818\n",
      "Epoch [6/10], Loss: 0.2836\n",
      "Epoch [6/10], Valid Accuracy: 92.5000, Valid Loss: 0.2661\n",
      "Epoch [7/10], Loss: 0.2670\n",
      "Epoch [7/10], Valid Accuracy: 92.8700, Valid Loss: 0.2521\n",
      "Epoch [8/10], Loss: 0.2529\n",
      "Epoch [8/10], Valid Accuracy: 93.3600, Valid Loss: 0.2396\n",
      "Epoch [9/10], Loss: 0.2404\n",
      "Epoch [9/10], Valid Accuracy: 93.5100, Valid Loss: 0.2292\n",
      "Epoch [10/10], Loss: 0.2291\n",
      "Epoch [10/10], Valid Accuracy: 93.8600, Valid Loss: 0.2193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.97, 10.29, 93.5, 97.67, 98.02, 93.86]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "accs = []\n",
    "for i in lrs:\n",
    "    net = get_model()\n",
    "    learning_rate = i\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    accs.append(val_acc)\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>10.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>93.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>97.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>98.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>93.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning rate  Val Accuracy\n",
       "0        1.00000          8.97\n",
       "1        0.10000         10.29\n",
       "2        0.01000         93.50\n",
       "3        0.00100         97.67\n",
       "4        0.00010         98.02\n",
       "5        0.00001         93.86"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'Learning rate': lrs, 'Val Accuracy': accs})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best two learning rates are 0.001 and 0.0001, with validation accuracy of 97.67 and 98.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4231\n",
      "Epoch [1/10], Valid Accuracy: 88.9600, Valid Loss: 0.3908\n",
      "Epoch [2/10], Loss: 0.3641\n",
      "Epoch [2/10], Valid Accuracy: 89.4500, Valid Loss: 0.3636\n",
      "Epoch [3/10], Loss: 0.3553\n",
      "Epoch [3/10], Valid Accuracy: 89.7800, Valid Loss: 0.3752\n",
      "Epoch [4/10], Loss: 0.3550\n",
      "Epoch [4/10], Valid Accuracy: 90.4400, Valid Loss: 0.3646\n",
      "Epoch [5/10], Loss: 0.3516\n",
      "Epoch [5/10], Valid Accuracy: 90.1500, Valid Loss: 0.3747\n",
      "Epoch [6/10], Loss: 0.3495\n",
      "Epoch [6/10], Valid Accuracy: 89.6500, Valid Loss: 0.3967\n",
      "Epoch [7/10], Loss: 0.3447\n",
      "Epoch [7/10], Valid Accuracy: 90.1200, Valid Loss: 0.3521\n",
      "Epoch [8/10], Loss: 0.3450\n",
      "Epoch [8/10], Valid Accuracy: 90.9400, Valid Loss: 0.3461\n",
      "Epoch [9/10], Loss: 0.3433\n",
      "Epoch [9/10], Valid Accuracy: 90.2700, Valid Loss: 0.3518\n",
      "Epoch [10/10], Loss: 0.3454\n",
      "Epoch [10/10], Valid Accuracy: 89.9400, Valid Loss: 0.3830\n",
      "Epoch [1/10], Loss: 0.3375\n",
      "Epoch [1/10], Valid Accuracy: 91.3300, Valid Loss: 0.2874\n",
      "Epoch [2/10], Loss: 0.2620\n",
      "Epoch [2/10], Valid Accuracy: 93.1300, Valid Loss: 0.2543\n",
      "Epoch [3/10], Loss: 0.2589\n",
      "Epoch [3/10], Valid Accuracy: 93.2100, Valid Loss: 0.2536\n",
      "Epoch [4/10], Loss: 0.2513\n",
      "Epoch [4/10], Valid Accuracy: 92.4300, Valid Loss: 0.3329\n",
      "Epoch [5/10], Loss: 0.2481\n",
      "Epoch [5/10], Valid Accuracy: 93.0900, Valid Loss: 0.2519\n",
      "Epoch [6/10], Loss: 0.2467\n",
      "Epoch [6/10], Valid Accuracy: 92.9300, Valid Loss: 0.2985\n",
      "Epoch [7/10], Loss: 0.2396\n",
      "Epoch [7/10], Valid Accuracy: 93.9600, Valid Loss: 0.2692\n",
      "Epoch [8/10], Loss: 0.2361\n",
      "Epoch [8/10], Valid Accuracy: 93.2400, Valid Loss: 0.3019\n",
      "Epoch [9/10], Loss: 0.2295\n",
      "Epoch [9/10], Valid Accuracy: 93.0200, Valid Loss: 0.3076\n",
      "Epoch [10/10], Loss: 0.2338\n",
      "Epoch [10/10], Valid Accuracy: 92.3400, Valid Loss: 0.3441\n",
      "Epoch [1/10], Loss: 0.3251\n",
      "Epoch [1/10], Valid Accuracy: 92.9300, Valid Loss: 0.2648\n",
      "Epoch [2/10], Loss: 0.2687\n",
      "Epoch [2/10], Valid Accuracy: 93.3500, Valid Loss: 0.2555\n",
      "Epoch [3/10], Loss: 0.2501\n",
      "Epoch [3/10], Valid Accuracy: 93.8900, Valid Loss: 0.2754\n",
      "Epoch [4/10], Loss: 0.2501\n",
      "Epoch [4/10], Valid Accuracy: 93.1800, Valid Loss: 0.3009\n",
      "Epoch [5/10], Loss: 0.2375\n",
      "Epoch [5/10], Valid Accuracy: 94.0000, Valid Loss: 0.2918\n",
      "Epoch [6/10], Loss: 0.2312\n",
      "Epoch [6/10], Valid Accuracy: 93.8000, Valid Loss: 0.2796\n",
      "Epoch [7/10], Loss: 0.2341\n",
      "Epoch [7/10], Valid Accuracy: 94.3900, Valid Loss: 0.2834\n",
      "Epoch [8/10], Loss: 0.2243\n",
      "Epoch [8/10], Valid Accuracy: 94.8900, Valid Loss: 0.2654\n",
      "Epoch [9/10], Loss: 0.2271\n",
      "Epoch [9/10], Valid Accuracy: 93.6200, Valid Loss: 0.3014\n",
      "Epoch [10/10], Loss: 0.2244\n",
      "Epoch [10/10], Valid Accuracy: 94.0200, Valid Loss: 0.3284\n",
      "Epoch [1/10], Loss: 0.3331\n",
      "Epoch [1/10], Valid Accuracy: 94.0900, Valid Loss: 0.2248\n",
      "Epoch [2/10], Loss: 0.2588\n",
      "Epoch [2/10], Valid Accuracy: 93.6900, Valid Loss: 0.2499\n",
      "Epoch [3/10], Loss: 0.2472\n",
      "Epoch [3/10], Valid Accuracy: 93.2200, Valid Loss: 0.2541\n",
      "Epoch [4/10], Loss: 0.2409\n",
      "Epoch [4/10], Valid Accuracy: 93.9700, Valid Loss: 0.2817\n",
      "Epoch [5/10], Loss: 0.2379\n",
      "Epoch [5/10], Valid Accuracy: 94.6700, Valid Loss: 0.2638\n",
      "Epoch [6/10], Loss: 0.2312\n",
      "Epoch [6/10], Valid Accuracy: 94.0400, Valid Loss: 0.2663\n",
      "Epoch [7/10], Loss: 0.2252\n",
      "Epoch [7/10], Valid Accuracy: 93.8400, Valid Loss: 0.2719\n",
      "Epoch [8/10], Loss: 0.2237\n",
      "Epoch [8/10], Valid Accuracy: 94.5600, Valid Loss: 0.2766\n",
      "Epoch [9/10], Loss: 0.2226\n",
      "Epoch [9/10], Valid Accuracy: 94.0600, Valid Loss: 0.3146\n",
      "Epoch [10/10], Loss: 0.2255\n",
      "Epoch [10/10], Valid Accuracy: 94.3000, Valid Loss: 0.3174\n",
      "Epoch [1/10], Loss: 0.3702\n",
      "Epoch [1/10], Valid Accuracy: 93.3500, Valid Loss: 0.2945\n",
      "Epoch [2/10], Loss: 0.2716\n",
      "Epoch [2/10], Valid Accuracy: 93.3700, Valid Loss: 0.2726\n",
      "Epoch [3/10], Loss: 0.2586\n",
      "Epoch [3/10], Valid Accuracy: 93.4400, Valid Loss: 0.2569\n",
      "Epoch [4/10], Loss: 0.2554\n",
      "Epoch [4/10], Valid Accuracy: 92.9000, Valid Loss: 0.3032\n",
      "Epoch [5/10], Loss: 0.2398\n",
      "Epoch [5/10], Valid Accuracy: 93.5100, Valid Loss: 0.2945\n",
      "Epoch [6/10], Loss: 0.2371\n",
      "Epoch [6/10], Valid Accuracy: 93.6800, Valid Loss: 0.2860\n",
      "Epoch [7/10], Loss: 0.2318\n",
      "Epoch [7/10], Valid Accuracy: 94.5900, Valid Loss: 0.2631\n",
      "Epoch [8/10], Loss: 0.2275\n",
      "Epoch [8/10], Valid Accuracy: 93.3600, Valid Loss: 0.3355\n",
      "Epoch [9/10], Loss: 0.2237\n",
      "Epoch [9/10], Valid Accuracy: 93.6900, Valid Loss: 0.3074\n",
      "Epoch [10/10], Loss: 0.2222\n",
      "Epoch [10/10], Valid Accuracy: 94.3300, Valid Loss: 0.3152\n",
      "Epoch [1/10], Loss: 0.3981\n",
      "Epoch [1/10], Valid Accuracy: 91.0800, Valid Loss: 0.4075\n",
      "Epoch [2/10], Loss: 0.2765\n",
      "Epoch [2/10], Valid Accuracy: 93.8800, Valid Loss: 0.2561\n",
      "Epoch [3/10], Loss: 0.2454\n",
      "Epoch [3/10], Valid Accuracy: 93.4400, Valid Loss: 0.2723\n",
      "Epoch [4/10], Loss: 0.2359\n",
      "Epoch [4/10], Valid Accuracy: 93.6900, Valid Loss: 0.2896\n",
      "Epoch [5/10], Loss: 0.2289\n",
      "Epoch [5/10], Valid Accuracy: 93.9400, Valid Loss: 0.3071\n",
      "Epoch [6/10], Loss: 0.2264\n",
      "Epoch [6/10], Valid Accuracy: 94.1200, Valid Loss: 0.2712\n",
      "Epoch [7/10], Loss: 0.2261\n",
      "Epoch [7/10], Valid Accuracy: 93.4300, Valid Loss: 0.3086\n",
      "Epoch [8/10], Loss: 0.2216\n",
      "Epoch [8/10], Valid Accuracy: 94.0600, Valid Loss: 0.3197\n",
      "Epoch [9/10], Loss: 0.2175\n",
      "Epoch [9/10], Valid Accuracy: 94.3100, Valid Loss: 0.3143\n",
      "Epoch [10/10], Loss: 0.2203\n",
      "Epoch [10/10], Valid Accuracy: 94.4000, Valid Loss: 0.3319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[89.94, 92.34, 94.02, 94.3, 94.33, 94.4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes = [10, 50, 100, 300, 1000, 2000]\n",
    "accs_layer = []\n",
    "for i in layer_sizes:\n",
    "    net = get_model_v2(M = i, p=0)\n",
    "    learning_rate = 0.01\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    accs_layer.append(val_acc)\n",
    "accs_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Size</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>89.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>92.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>94.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>94.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>94.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>94.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layer Size  Val Accuracy\n",
       "0          10         89.94\n",
       "1          50         92.34\n",
       "2         100         94.02\n",
       "3         300         94.30\n",
       "4        1000         94.33\n",
       "5        2000         94.40"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'Layer Size': layer_sizes, 'Val Accuracy': accs_layer})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best layer size is 1000, with the validation accuracy being 94.33. The layer sizes of 100, 300, 1000, and 2000 might overfit, since the marginal increase of validation accuracy is very small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1999\n",
      "Epoch [1/20], Valid Accuracy: 97.1700, Valid Loss: 0.0945\n",
      "Epoch [2/20], Loss: 0.0872\n",
      "Epoch [2/20], Valid Accuracy: 97.4400, Valid Loss: 0.0855\n",
      "Epoch [3/20], Loss: 0.0630\n",
      "Epoch [3/20], Valid Accuracy: 97.1100, Valid Loss: 0.0941\n",
      "Epoch [4/20], Loss: 0.0477\n",
      "Epoch [4/20], Valid Accuracy: 97.4700, Valid Loss: 0.0903\n",
      "Epoch [5/20], Loss: 0.0382\n",
      "Epoch [5/20], Valid Accuracy: 97.4300, Valid Loss: 0.0881\n",
      "Epoch [6/20], Loss: 0.0299\n",
      "Epoch [6/20], Valid Accuracy: 97.1300, Valid Loss: 0.1091\n",
      "Epoch [7/20], Loss: 0.0276\n",
      "Epoch [7/20], Valid Accuracy: 97.2700, Valid Loss: 0.1123\n",
      "Epoch [8/20], Loss: 0.0230\n",
      "Epoch [8/20], Valid Accuracy: 97.5600, Valid Loss: 0.1202\n",
      "Epoch [9/20], Loss: 0.0218\n",
      "Epoch [9/20], Valid Accuracy: 97.8700, Valid Loss: 0.1005\n",
      "Epoch [10/20], Loss: 0.0189\n",
      "Epoch [10/20], Valid Accuracy: 97.7900, Valid Loss: 0.1054\n",
      "Epoch [11/20], Loss: 0.0193\n",
      "Epoch [11/20], Valid Accuracy: 98.0900, Valid Loss: 0.1005\n",
      "Epoch [12/20], Loss: 0.0194\n",
      "Epoch [12/20], Valid Accuracy: 98.0300, Valid Loss: 0.1097\n",
      "Epoch [13/20], Loss: 0.0152\n",
      "Epoch [13/20], Valid Accuracy: 98.0600, Valid Loss: 0.1106\n",
      "Epoch [14/20], Loss: 0.0173\n",
      "Epoch [14/20], Valid Accuracy: 98.1200, Valid Loss: 0.1097\n",
      "Epoch [15/20], Loss: 0.0157\n",
      "Epoch [15/20], Valid Accuracy: 97.7400, Valid Loss: 0.1246\n",
      "Epoch [16/20], Loss: 0.0133\n",
      "Epoch [16/20], Valid Accuracy: 97.9400, Valid Loss: 0.1223\n",
      "Epoch [17/20], Loss: 0.0136\n",
      "Epoch [17/20], Valid Accuracy: 98.0300, Valid Loss: 0.1419\n",
      "Epoch [18/20], Loss: 0.0116\n",
      "Epoch [18/20], Valid Accuracy: 98.0100, Valid Loss: 0.1401\n",
      "Epoch [19/20], Loss: 0.0134\n",
      "Epoch [19/20], Valid Accuracy: 97.9000, Valid Loss: 0.1429\n",
      "Epoch [20/20], Loss: 0.0129\n",
      "Epoch [20/20], Valid Accuracy: 97.7500, Valid Loss: 0.1571\n",
      "Epoch [1/20], Loss: 0.2044\n",
      "Epoch [1/20], Valid Accuracy: 96.7900, Valid Loss: 0.1069\n",
      "Epoch [2/20], Loss: 0.0919\n",
      "Epoch [2/20], Valid Accuracy: 97.6000, Valid Loss: 0.0830\n",
      "Epoch [3/20], Loss: 0.0666\n",
      "Epoch [3/20], Valid Accuracy: 96.8600, Valid Loss: 0.0986\n",
      "Epoch [4/20], Loss: 0.0536\n",
      "Epoch [4/20], Valid Accuracy: 97.8700, Valid Loss: 0.0689\n",
      "Epoch [5/20], Loss: 0.0460\n",
      "Epoch [5/20], Valid Accuracy: 97.2400, Valid Loss: 0.0891\n",
      "Epoch [6/20], Loss: 0.0417\n",
      "Epoch [6/20], Valid Accuracy: 97.6900, Valid Loss: 0.0785\n",
      "Epoch [7/20], Loss: 0.0361\n",
      "Epoch [7/20], Valid Accuracy: 97.5700, Valid Loss: 0.0882\n",
      "Epoch [8/20], Loss: 0.0329\n",
      "Epoch [8/20], Valid Accuracy: 97.6900, Valid Loss: 0.0861\n",
      "Epoch [9/20], Loss: 0.0332\n",
      "Epoch [9/20], Valid Accuracy: 97.6300, Valid Loss: 0.0886\n",
      "Epoch [10/20], Loss: 0.0294\n",
      "Epoch [10/20], Valid Accuracy: 97.5000, Valid Loss: 0.0926\n",
      "Epoch [11/20], Loss: 0.0301\n",
      "Epoch [11/20], Valid Accuracy: 97.9800, Valid Loss: 0.0766\n",
      "Epoch [12/20], Loss: 0.0276\n",
      "Epoch [12/20], Valid Accuracy: 97.9400, Valid Loss: 0.0800\n",
      "Epoch [13/20], Loss: 0.0261\n",
      "Epoch [13/20], Valid Accuracy: 97.6100, Valid Loss: 0.0915\n",
      "Epoch [14/20], Loss: 0.0256\n",
      "Epoch [14/20], Valid Accuracy: 97.7600, Valid Loss: 0.0947\n",
      "Epoch [15/20], Loss: 0.0248\n",
      "Epoch [15/20], Valid Accuracy: 97.9800, Valid Loss: 0.0891\n",
      "Epoch [16/20], Loss: 0.0239\n",
      "Epoch [16/20], Valid Accuracy: 97.9500, Valid Loss: 0.0793\n",
      "Epoch [17/20], Loss: 0.0254\n",
      "Epoch [17/20], Valid Accuracy: 98.0200, Valid Loss: 0.0776\n",
      "Epoch [18/20], Loss: 0.0223\n",
      "Epoch [18/20], Valid Accuracy: 97.9600, Valid Loss: 0.0837\n",
      "Epoch [19/20], Loss: 0.0258\n",
      "Epoch [19/20], Valid Accuracy: 97.6400, Valid Loss: 0.0941\n",
      "Epoch [20/20], Loss: 0.0238\n",
      "Epoch [20/20], Valid Accuracy: 97.5600, Valid Loss: 0.0981\n",
      "Epoch [1/20], Loss: 0.2082\n",
      "Epoch [1/20], Valid Accuracy: 96.4600, Valid Loss: 0.1185\n",
      "Epoch [2/20], Loss: 0.1094\n",
      "Epoch [2/20], Valid Accuracy: 96.5200, Valid Loss: 0.1084\n",
      "Epoch [3/20], Loss: 0.0943\n",
      "Epoch [3/20], Valid Accuracy: 97.2400, Valid Loss: 0.0873\n",
      "Epoch [4/20], Loss: 0.0859\n",
      "Epoch [4/20], Valid Accuracy: 97.3900, Valid Loss: 0.0824\n",
      "Epoch [5/20], Loss: 0.0798\n",
      "Epoch [5/20], Valid Accuracy: 97.1700, Valid Loss: 0.0953\n",
      "Epoch [6/20], Loss: 0.0760\n",
      "Epoch [6/20], Valid Accuracy: 96.8300, Valid Loss: 0.0992\n",
      "Epoch [7/20], Loss: 0.0732\n",
      "Epoch [7/20], Valid Accuracy: 97.0200, Valid Loss: 0.0929\n",
      "Epoch [8/20], Loss: 0.0722\n",
      "Epoch [8/20], Valid Accuracy: 97.2400, Valid Loss: 0.0955\n",
      "Epoch [9/20], Loss: 0.0702\n",
      "Epoch [9/20], Valid Accuracy: 97.6300, Valid Loss: 0.0803\n",
      "Epoch [10/20], Loss: 0.0683\n",
      "Epoch [10/20], Valid Accuracy: 97.4600, Valid Loss: 0.0783\n",
      "Epoch [11/20], Loss: 0.0668\n",
      "Epoch [11/20], Valid Accuracy: 96.9400, Valid Loss: 0.0953\n",
      "Epoch [12/20], Loss: 0.0679\n",
      "Epoch [12/20], Valid Accuracy: 97.3500, Valid Loss: 0.0867\n",
      "Epoch [13/20], Loss: 0.0644\n",
      "Epoch [13/20], Valid Accuracy: 97.5500, Valid Loss: 0.0820\n",
      "Epoch [14/20], Loss: 0.0651\n",
      "Epoch [14/20], Valid Accuracy: 97.5900, Valid Loss: 0.0813\n",
      "Epoch [15/20], Loss: 0.0659\n",
      "Epoch [15/20], Valid Accuracy: 97.6400, Valid Loss: 0.0778\n",
      "Epoch [16/20], Loss: 0.0620\n",
      "Epoch [16/20], Valid Accuracy: 97.0900, Valid Loss: 0.0946\n",
      "Epoch [17/20], Loss: 0.0629\n",
      "Epoch [17/20], Valid Accuracy: 97.2600, Valid Loss: 0.0881\n",
      "Epoch [18/20], Loss: 0.0634\n",
      "Epoch [18/20], Valid Accuracy: 97.5600, Valid Loss: 0.0818\n",
      "Epoch [19/20], Loss: 0.0603\n",
      "Epoch [19/20], Valid Accuracy: 97.3700, Valid Loss: 0.0854\n",
      "Epoch [20/20], Loss: 0.0630\n",
      "Epoch [20/20], Valid Accuracy: 97.4400, Valid Loss: 0.0790\n",
      "Epoch [1/20], Loss: 0.2709\n",
      "Epoch [1/20], Valid Accuracy: 94.7100, Valid Loss: 0.1878\n",
      "Epoch [2/20], Loss: 0.2028\n",
      "Epoch [2/20], Valid Accuracy: 94.4000, Valid Loss: 0.1956\n",
      "Epoch [3/20], Loss: 0.1897\n",
      "Epoch [3/20], Valid Accuracy: 94.8800, Valid Loss: 0.1822\n",
      "Epoch [4/20], Loss: 0.1794\n",
      "Epoch [4/20], Valid Accuracy: 94.4200, Valid Loss: 0.1855\n",
      "Epoch [5/20], Loss: 0.1759\n",
      "Epoch [5/20], Valid Accuracy: 95.4100, Valid Loss: 0.1706\n",
      "Epoch [6/20], Loss: 0.1729\n",
      "Epoch [6/20], Valid Accuracy: 95.7000, Valid Loss: 0.1542\n",
      "Epoch [7/20], Loss: 0.1723\n",
      "Epoch [7/20], Valid Accuracy: 95.7500, Valid Loss: 0.1538\n",
      "Epoch [8/20], Loss: 0.1691\n",
      "Epoch [8/20], Valid Accuracy: 95.0100, Valid Loss: 0.1691\n",
      "Epoch [9/20], Loss: 0.1698\n",
      "Epoch [9/20], Valid Accuracy: 95.3100, Valid Loss: 0.1678\n",
      "Epoch [10/20], Loss: 0.1686\n",
      "Epoch [10/20], Valid Accuracy: 95.7200, Valid Loss: 0.1542\n",
      "Epoch [11/20], Loss: 0.1689\n",
      "Epoch [11/20], Valid Accuracy: 95.7000, Valid Loss: 0.1610\n",
      "Epoch [12/20], Loss: 0.1677\n",
      "Epoch [12/20], Valid Accuracy: 95.7700, Valid Loss: 0.1533\n",
      "Epoch [13/20], Loss: 0.1677\n",
      "Epoch [13/20], Valid Accuracy: 95.5800, Valid Loss: 0.1550\n",
      "Epoch [14/20], Loss: 0.1669\n",
      "Epoch [14/20], Valid Accuracy: 95.6700, Valid Loss: 0.1543\n",
      "Epoch [15/20], Loss: 0.1670\n",
      "Epoch [15/20], Valid Accuracy: 95.8500, Valid Loss: 0.1544\n",
      "Epoch [16/20], Loss: 0.1660\n",
      "Epoch [16/20], Valid Accuracy: 95.3100, Valid Loss: 0.1606\n",
      "Epoch [17/20], Loss: 0.1659\n",
      "Epoch [17/20], Valid Accuracy: 95.5400, Valid Loss: 0.1629\n",
      "Epoch [18/20], Loss: 0.1664\n",
      "Epoch [18/20], Valid Accuracy: 95.8300, Valid Loss: 0.1534\n",
      "Epoch [19/20], Loss: 0.1658\n",
      "Epoch [19/20], Valid Accuracy: 96.2600, Valid Loss: 0.1489\n",
      "Epoch [20/20], Loss: 0.1660\n",
      "Epoch [20/20], Valid Accuracy: 95.4500, Valid Loss: 0.1645\n",
      "Epoch [1/20], Loss: 0.5397\n",
      "Epoch [1/20], Valid Accuracy: 84.2100, Valid Loss: 0.5345\n",
      "Epoch [2/20], Loss: 0.4994\n",
      "Epoch [2/20], Valid Accuracy: 88.3900, Valid Loss: 0.4798\n",
      "Epoch [3/20], Loss: 0.4864\n",
      "Epoch [3/20], Valid Accuracy: 88.8600, Valid Loss: 0.4643\n",
      "Epoch [4/20], Loss: 0.4813\n",
      "Epoch [4/20], Valid Accuracy: 89.5600, Valid Loss: 0.4512\n",
      "Epoch [5/20], Loss: 0.4756\n",
      "Epoch [5/20], Valid Accuracy: 89.3700, Valid Loss: 0.4586\n",
      "Epoch [6/20], Loss: 0.4729\n",
      "Epoch [6/20], Valid Accuracy: 89.3200, Valid Loss: 0.4694\n",
      "Epoch [7/20], Loss: 0.4723\n",
      "Epoch [7/20], Valid Accuracy: 88.2500, Valid Loss: 0.4853\n",
      "Epoch [8/20], Loss: 0.4715\n",
      "Epoch [8/20], Valid Accuracy: 89.4600, Valid Loss: 0.4382\n",
      "Epoch [9/20], Loss: 0.4690\n",
      "Epoch [9/20], Valid Accuracy: 89.6700, Valid Loss: 0.4445\n",
      "Epoch [10/20], Loss: 0.4689\n",
      "Epoch [10/20], Valid Accuracy: 89.8500, Valid Loss: 0.4618\n",
      "Epoch [11/20], Loss: 0.4678\n",
      "Epoch [11/20], Valid Accuracy: 89.4900, Valid Loss: 0.4556\n",
      "Epoch [12/20], Loss: 0.4680\n",
      "Epoch [12/20], Valid Accuracy: 89.0100, Valid Loss: 0.4473\n",
      "Epoch [13/20], Loss: 0.4675\n",
      "Epoch [13/20], Valid Accuracy: 89.0600, Valid Loss: 0.4587\n",
      "Epoch [14/20], Loss: 0.4668\n",
      "Epoch [14/20], Valid Accuracy: 89.5700, Valid Loss: 0.4524\n",
      "Epoch [15/20], Loss: 0.4665\n",
      "Epoch [15/20], Valid Accuracy: 89.5800, Valid Loss: 0.4565\n",
      "Epoch [16/20], Loss: 0.4674\n",
      "Epoch [16/20], Valid Accuracy: 89.2400, Valid Loss: 0.4490\n",
      "Epoch [17/20], Loss: 0.4665\n",
      "Epoch [17/20], Valid Accuracy: 89.0700, Valid Loss: 0.4591\n",
      "Epoch [18/20], Loss: 0.4674\n",
      "Epoch [18/20], Valid Accuracy: 89.4300, Valid Loss: 0.4477\n",
      "Epoch [19/20], Loss: 0.4665\n",
      "Epoch [19/20], Valid Accuracy: 89.8600, Valid Loss: 0.4432\n",
      "Epoch [20/20], Loss: 0.4667\n",
      "Epoch [20/20], Valid Accuracy: 89.4900, Valid Loss: 0.4485\n",
      "Epoch [1/20], Loss: 0.8723\n",
      "Epoch [1/20], Valid Accuracy: 84.0900, Valid Loss: 0.8141\n",
      "Epoch [2/20], Loss: 0.8415\n",
      "Epoch [2/20], Valid Accuracy: 83.9100, Valid Loss: 0.8169\n",
      "Epoch [3/20], Loss: 0.8326\n",
      "Epoch [3/20], Valid Accuracy: 84.7300, Valid Loss: 0.8063\n",
      "Epoch [4/20], Loss: 0.8270\n",
      "Epoch [4/20], Valid Accuracy: 85.4500, Valid Loss: 0.7898\n",
      "Epoch [5/20], Loss: 0.8224\n",
      "Epoch [5/20], Valid Accuracy: 85.3300, Valid Loss: 0.7980\n",
      "Epoch [6/20], Loss: 0.8199\n",
      "Epoch [6/20], Valid Accuracy: 85.8000, Valid Loss: 0.7881\n",
      "Epoch [7/20], Loss: 0.8180\n",
      "Epoch [7/20], Valid Accuracy: 85.3100, Valid Loss: 0.7842\n",
      "Epoch [8/20], Loss: 0.8179\n",
      "Epoch [8/20], Valid Accuracy: 83.8400, Valid Loss: 0.8007\n",
      "Epoch [9/20], Loss: 0.8182\n",
      "Epoch [9/20], Valid Accuracy: 84.6200, Valid Loss: 0.8035\n",
      "Epoch [10/20], Loss: 0.8186\n",
      "Epoch [10/20], Valid Accuracy: 85.5200, Valid Loss: 0.7857\n",
      "Epoch [11/20], Loss: 0.8189\n",
      "Epoch [11/20], Valid Accuracy: 84.3500, Valid Loss: 0.7958\n",
      "Epoch [12/20], Loss: 0.8179\n",
      "Epoch [12/20], Valid Accuracy: 83.8300, Valid Loss: 0.8048\n",
      "Epoch [13/20], Loss: 0.8189\n",
      "Epoch [13/20], Valid Accuracy: 84.9100, Valid Loss: 0.7900\n",
      "Epoch [14/20], Loss: 0.8184\n",
      "Epoch [14/20], Valid Accuracy: 84.9300, Valid Loss: 0.7972\n",
      "Epoch [15/20], Loss: 0.8188\n",
      "Epoch [15/20], Valid Accuracy: 83.8300, Valid Loss: 0.8017\n",
      "Epoch [16/20], Loss: 0.8185\n",
      "Epoch [16/20], Valid Accuracy: 85.9200, Valid Loss: 0.8024\n",
      "Epoch [17/20], Loss: 0.8183\n",
      "Epoch [17/20], Valid Accuracy: 84.5100, Valid Loss: 0.7918\n",
      "Epoch [18/20], Loss: 0.8175\n",
      "Epoch [18/20], Valid Accuracy: 84.7200, Valid Loss: 0.7919\n",
      "Epoch [19/20], Loss: 0.8178\n",
      "Epoch [19/20], Valid Accuracy: 84.0500, Valid Loss: 0.8095\n",
      "Epoch [20/20], Loss: 0.8180\n",
      "Epoch [20/20], Valid Accuracy: 83.7700, Valid Loss: 0.7972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[97.75, 97.56, 97.44, 95.45, 89.49, 83.77]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wds = [0, 0.0001, 0.001, 0.01, 0.1, 0.3]\n",
    "accs_wds = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for i in wds:\n",
    "    net = get_model_v2(M = 300, p=0)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = i)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    accs_wds.append(val_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "accs_wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>train loss</th>\n",
       "      <th>validation loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.75</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>0.157058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.56</td>\n",
       "      <td>0.023799</td>\n",
       "      <td>0.098141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.44</td>\n",
       "      <td>0.063027</td>\n",
       "      <td>0.079019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.45</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.164493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.49</td>\n",
       "      <td>0.466684</td>\n",
       "      <td>0.448452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>83.77</td>\n",
       "      <td>0.818007</td>\n",
       "      <td>0.797153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight Decay  Val Accuracy  train loss  validation loss\n",
       "0        0.0000         97.75    0.012886         0.157058\n",
       "1        0.0001         97.56    0.023799         0.098141\n",
       "2        0.0010         97.44    0.063027         0.079019\n",
       "3        0.0100         95.45    0.166016         0.164493\n",
       "4        0.1000         89.49    0.466684         0.448452\n",
       "5        0.3000         83.77    0.818007         0.797153"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'Weight Decay': wds, 'Val Accuracy': accs_wds, 'train loss': train_losses, 'validation loss': val_losses})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2010\n",
      "Epoch [1/20], Valid Accuracy: 97.0400, Valid Loss: 0.0994\n",
      "Epoch [2/20], Loss: 0.0898\n",
      "Epoch [2/20], Valid Accuracy: 97.0000, Valid Loss: 0.1020\n",
      "Epoch [3/20], Loss: 0.0618\n",
      "Epoch [3/20], Valid Accuracy: 97.2100, Valid Loss: 0.0862\n",
      "Epoch [4/20], Loss: 0.0482\n",
      "Epoch [4/20], Valid Accuracy: 97.7100, Valid Loss: 0.0789\n",
      "Epoch [5/20], Loss: 0.0395\n",
      "Epoch [5/20], Valid Accuracy: 97.6400, Valid Loss: 0.0899\n",
      "Epoch [6/20], Loss: 0.0326\n",
      "Epoch [6/20], Valid Accuracy: 97.9600, Valid Loss: 0.0874\n",
      "Epoch [7/20], Loss: 0.0282\n",
      "Epoch [7/20], Valid Accuracy: 97.4700, Valid Loss: 0.1054\n",
      "Epoch [8/20], Loss: 0.0230\n",
      "Epoch [8/20], Valid Accuracy: 97.5700, Valid Loss: 0.1026\n",
      "Epoch [9/20], Loss: 0.0248\n",
      "Epoch [9/20], Valid Accuracy: 97.7700, Valid Loss: 0.1083\n",
      "Epoch [10/20], Loss: 0.0191\n",
      "Epoch [10/20], Valid Accuracy: 97.7200, Valid Loss: 0.1070\n",
      "Epoch [11/20], Loss: 0.0200\n",
      "Epoch [11/20], Valid Accuracy: 97.8400, Valid Loss: 0.1119\n",
      "Epoch [12/20], Loss: 0.0169\n",
      "Epoch [12/20], Valid Accuracy: 97.6500, Valid Loss: 0.1270\n",
      "Epoch [13/20], Loss: 0.0164\n",
      "Epoch [13/20], Valid Accuracy: 97.4300, Valid Loss: 0.1422\n",
      "Epoch [14/20], Loss: 0.0181\n",
      "Epoch [14/20], Valid Accuracy: 97.8800, Valid Loss: 0.1199\n",
      "Epoch [15/20], Loss: 0.0132\n",
      "Epoch [15/20], Valid Accuracy: 97.9700, Valid Loss: 0.1215\n",
      "Epoch [16/20], Loss: 0.0143\n",
      "Epoch [16/20], Valid Accuracy: 97.7700, Valid Loss: 0.1304\n",
      "Epoch [17/20], Loss: 0.0142\n",
      "Epoch [17/20], Valid Accuracy: 97.8500, Valid Loss: 0.1410\n",
      "Epoch [18/20], Loss: 0.0118\n",
      "Epoch [18/20], Valid Accuracy: 97.7900, Valid Loss: 0.1418\n",
      "Epoch [19/20], Loss: 0.0159\n",
      "Epoch [19/20], Valid Accuracy: 97.8300, Valid Loss: 0.1702\n",
      "Epoch [20/20], Loss: 0.0126\n",
      "Epoch [20/20], Valid Accuracy: 97.7600, Valid Loss: 0.1597\n",
      "Epoch [1/20], Loss: 0.2288\n",
      "Epoch [1/20], Valid Accuracy: 96.4600, Valid Loss: 0.1166\n",
      "Epoch [2/20], Loss: 0.0928\n",
      "Epoch [2/20], Valid Accuracy: 96.9100, Valid Loss: 0.0992\n",
      "Epoch [3/20], Loss: 0.0660\n",
      "Epoch [3/20], Valid Accuracy: 97.5100, Valid Loss: 0.0808\n",
      "Epoch [4/20], Loss: 0.0499\n",
      "Epoch [4/20], Valid Accuracy: 97.2500, Valid Loss: 0.0988\n",
      "Epoch [5/20], Loss: 0.0412\n",
      "Epoch [5/20], Valid Accuracy: 97.3400, Valid Loss: 0.0996\n",
      "Epoch [6/20], Loss: 0.0345\n",
      "Epoch [6/20], Valid Accuracy: 97.5900, Valid Loss: 0.0908\n",
      "Epoch [7/20], Loss: 0.0285\n",
      "Epoch [7/20], Valid Accuracy: 97.5500, Valid Loss: 0.0966\n",
      "Epoch [8/20], Loss: 0.0255\n",
      "Epoch [8/20], Valid Accuracy: 97.7600, Valid Loss: 0.1014\n",
      "Epoch [9/20], Loss: 0.0227\n",
      "Epoch [9/20], Valid Accuracy: 97.4800, Valid Loss: 0.1219\n",
      "Epoch [10/20], Loss: 0.0218\n",
      "Epoch [10/20], Valid Accuracy: 97.6600, Valid Loss: 0.1125\n",
      "Epoch [11/20], Loss: 0.0198\n",
      "Epoch [11/20], Valid Accuracy: 97.7000, Valid Loss: 0.1257\n",
      "Epoch [12/20], Loss: 0.0189\n",
      "Epoch [12/20], Valid Accuracy: 97.7500, Valid Loss: 0.1232\n",
      "Epoch [13/20], Loss: 0.0171\n",
      "Epoch [13/20], Valid Accuracy: 97.9900, Valid Loss: 0.1130\n",
      "Epoch [14/20], Loss: 0.0186\n",
      "Epoch [14/20], Valid Accuracy: 97.9000, Valid Loss: 0.1217\n",
      "Epoch [15/20], Loss: 0.0146\n",
      "Epoch [15/20], Valid Accuracy: 98.0800, Valid Loss: 0.1234\n",
      "Epoch [16/20], Loss: 0.0136\n",
      "Epoch [16/20], Valid Accuracy: 97.9900, Valid Loss: 0.1316\n",
      "Epoch [17/20], Loss: 0.0168\n",
      "Epoch [17/20], Valid Accuracy: 97.6500, Valid Loss: 0.1578\n",
      "Epoch [18/20], Loss: 0.0125\n",
      "Epoch [18/20], Valid Accuracy: 97.8000, Valid Loss: 0.1486\n",
      "Epoch [19/20], Loss: 0.0108\n",
      "Epoch [19/20], Valid Accuracy: 98.0600, Valid Loss: 0.1412\n",
      "Epoch [20/20], Loss: 0.0161\n",
      "Epoch [20/20], Valid Accuracy: 97.6900, Valid Loss: 0.1663\n",
      "Epoch [1/20], Loss: 0.2620\n",
      "Epoch [1/20], Valid Accuracy: 96.4300, Valid Loss: 0.1173\n",
      "Epoch [2/20], Loss: 0.0957\n",
      "Epoch [2/20], Valid Accuracy: 97.0200, Valid Loss: 0.0948\n",
      "Epoch [3/20], Loss: 0.0679\n",
      "Epoch [3/20], Valid Accuracy: 97.3200, Valid Loss: 0.0841\n",
      "Epoch [4/20], Loss: 0.0495\n",
      "Epoch [4/20], Valid Accuracy: 97.4000, Valid Loss: 0.0882\n",
      "Epoch [5/20], Loss: 0.0401\n",
      "Epoch [5/20], Valid Accuracy: 97.6500, Valid Loss: 0.0881\n",
      "Epoch [6/20], Loss: 0.0352\n",
      "Epoch [6/20], Valid Accuracy: 97.9200, Valid Loss: 0.0846\n",
      "Epoch [7/20], Loss: 0.0288\n",
      "Epoch [7/20], Valid Accuracy: 97.5300, Valid Loss: 0.0919\n",
      "Epoch [8/20], Loss: 0.0249\n",
      "Epoch [8/20], Valid Accuracy: 97.8800, Valid Loss: 0.0870\n",
      "Epoch [9/20], Loss: 0.0248\n",
      "Epoch [9/20], Valid Accuracy: 97.7700, Valid Loss: 0.0987\n",
      "Epoch [10/20], Loss: 0.0191\n",
      "Epoch [10/20], Valid Accuracy: 97.8900, Valid Loss: 0.0988\n",
      "Epoch [11/20], Loss: 0.0166\n",
      "Epoch [11/20], Valid Accuracy: 97.8100, Valid Loss: 0.1096\n",
      "Epoch [12/20], Loss: 0.0211\n",
      "Epoch [12/20], Valid Accuracy: 97.8600, Valid Loss: 0.1213\n",
      "Epoch [13/20], Loss: 0.0168\n",
      "Epoch [13/20], Valid Accuracy: 97.7500, Valid Loss: 0.1344\n",
      "Epoch [14/20], Loss: 0.0157\n",
      "Epoch [14/20], Valid Accuracy: 97.7800, Valid Loss: 0.1357\n",
      "Epoch [15/20], Loss: 0.0159\n",
      "Epoch [15/20], Valid Accuracy: 97.7900, Valid Loss: 0.1218\n",
      "Epoch [16/20], Loss: 0.0145\n",
      "Epoch [16/20], Valid Accuracy: 97.9500, Valid Loss: 0.1278\n",
      "Epoch [17/20], Loss: 0.0133\n",
      "Epoch [17/20], Valid Accuracy: 97.9100, Valid Loss: 0.1440\n",
      "Epoch [18/20], Loss: 0.0144\n",
      "Epoch [18/20], Valid Accuracy: 97.8100, Valid Loss: 0.1506\n",
      "Epoch [19/20], Loss: 0.0135\n",
      "Epoch [19/20], Valid Accuracy: 97.8900, Valid Loss: 0.1622\n",
      "Epoch [20/20], Loss: 0.0154\n",
      "Epoch [20/20], Valid Accuracy: 98.1600, Valid Loss: 0.1499\n",
      "Epoch [1/20], Loss: 0.3351\n",
      "Epoch [1/20], Valid Accuracy: 95.6700, Valid Loss: 0.1384\n",
      "Epoch [2/20], Loss: 0.1038\n",
      "Epoch [2/20], Valid Accuracy: 97.2900, Valid Loss: 0.0895\n",
      "Epoch [3/20], Loss: 0.0729\n",
      "Epoch [3/20], Valid Accuracy: 97.5900, Valid Loss: 0.0806\n",
      "Epoch [4/20], Loss: 0.0538\n",
      "Epoch [4/20], Valid Accuracy: 97.6900, Valid Loss: 0.0863\n",
      "Epoch [5/20], Loss: 0.0440\n",
      "Epoch [5/20], Valid Accuracy: 97.5100, Valid Loss: 0.0862\n",
      "Epoch [6/20], Loss: 0.0331\n",
      "Epoch [6/20], Valid Accuracy: 97.5900, Valid Loss: 0.0933\n",
      "Epoch [7/20], Loss: 0.0308\n",
      "Epoch [7/20], Valid Accuracy: 97.6400, Valid Loss: 0.0912\n",
      "Epoch [8/20], Loss: 0.0249\n",
      "Epoch [8/20], Valid Accuracy: 97.9400, Valid Loss: 0.0863\n",
      "Epoch [9/20], Loss: 0.0258\n",
      "Epoch [9/20], Valid Accuracy: 97.7400, Valid Loss: 0.1031\n",
      "Epoch [10/20], Loss: 0.0208\n",
      "Epoch [10/20], Valid Accuracy: 97.4100, Valid Loss: 0.1219\n",
      "Epoch [11/20], Loss: 0.0211\n",
      "Epoch [11/20], Valid Accuracy: 97.8100, Valid Loss: 0.1158\n",
      "Epoch [12/20], Loss: 0.0181\n",
      "Epoch [12/20], Valid Accuracy: 97.9900, Valid Loss: 0.1041\n",
      "Epoch [13/20], Loss: 0.0167\n",
      "Epoch [13/20], Valid Accuracy: 97.8900, Valid Loss: 0.1201\n",
      "Epoch [14/20], Loss: 0.0171\n",
      "Epoch [14/20], Valid Accuracy: 97.8400, Valid Loss: 0.1282\n",
      "Epoch [15/20], Loss: 0.0182\n",
      "Epoch [15/20], Valid Accuracy: 97.9700, Valid Loss: 0.1163\n",
      "Epoch [16/20], Loss: 0.0175\n",
      "Epoch [16/20], Valid Accuracy: 98.0000, Valid Loss: 0.1148\n",
      "Epoch [17/20], Loss: 0.0130\n",
      "Epoch [17/20], Valid Accuracy: 98.0100, Valid Loss: 0.1267\n",
      "Epoch [18/20], Loss: 0.0127\n",
      "Epoch [18/20], Valid Accuracy: 97.6900, Valid Loss: 0.1473\n",
      "Epoch [19/20], Loss: 0.0153\n",
      "Epoch [19/20], Valid Accuracy: 97.7600, Valid Loss: 0.1591\n",
      "Epoch [20/20], Loss: 0.0098\n",
      "Epoch [20/20], Valid Accuracy: 97.7900, Valid Loss: 0.1532\n",
      "Epoch [1/20], Loss: 0.5336\n",
      "Epoch [1/20], Valid Accuracy: 94.7000, Valid Loss: 0.1826\n",
      "Epoch [2/20], Loss: 0.1256\n",
      "Epoch [2/20], Valid Accuracy: 97.0600, Valid Loss: 0.0956\n",
      "Epoch [3/20], Loss: 0.0804\n",
      "Epoch [3/20], Valid Accuracy: 97.4800, Valid Loss: 0.0892\n",
      "Epoch [4/20], Loss: 0.0614\n",
      "Epoch [4/20], Valid Accuracy: 97.6500, Valid Loss: 0.0823\n",
      "Epoch [5/20], Loss: 0.0477\n",
      "Epoch [5/20], Valid Accuracy: 97.9100, Valid Loss: 0.0783\n",
      "Epoch [6/20], Loss: 0.0369\n",
      "Epoch [6/20], Valid Accuracy: 97.7700, Valid Loss: 0.0838\n",
      "Epoch [7/20], Loss: 0.0328\n",
      "Epoch [7/20], Valid Accuracy: 97.8800, Valid Loss: 0.0847\n",
      "Epoch [8/20], Loss: 0.0273\n",
      "Epoch [8/20], Valid Accuracy: 97.7500, Valid Loss: 0.0955\n",
      "Epoch [9/20], Loss: 0.0241\n",
      "Epoch [9/20], Valid Accuracy: 97.7100, Valid Loss: 0.0961\n",
      "Epoch [10/20], Loss: 0.0227\n",
      "Epoch [10/20], Valid Accuracy: 97.7800, Valid Loss: 0.0979\n",
      "Epoch [11/20], Loss: 0.0203\n",
      "Epoch [11/20], Valid Accuracy: 97.6900, Valid Loss: 0.1098\n",
      "Epoch [12/20], Loss: 0.0172\n",
      "Epoch [12/20], Valid Accuracy: 97.6600, Valid Loss: 0.1317\n",
      "Epoch [13/20], Loss: 0.0168\n",
      "Epoch [13/20], Valid Accuracy: 97.4500, Valid Loss: 0.1296\n",
      "Epoch [14/20], Loss: 0.0169\n",
      "Epoch [14/20], Valid Accuracy: 97.9400, Valid Loss: 0.1266\n",
      "Epoch [15/20], Loss: 0.0159\n",
      "Epoch [15/20], Valid Accuracy: 97.6900, Valid Loss: 0.1337\n",
      "Epoch [16/20], Loss: 0.0129\n",
      "Epoch [16/20], Valid Accuracy: 97.6600, Valid Loss: 0.1304\n",
      "Epoch [17/20], Loss: 0.0143\n",
      "Epoch [17/20], Valid Accuracy: 97.8800, Valid Loss: 0.1410\n",
      "Epoch [18/20], Loss: 0.0148\n",
      "Epoch [18/20], Valid Accuracy: 97.7900, Valid Loss: 0.1469\n",
      "Epoch [19/20], Loss: 0.0125\n",
      "Epoch [19/20], Valid Accuracy: 97.8300, Valid Loss: 0.1507\n",
      "Epoch [20/20], Loss: 0.0145\n",
      "Epoch [20/20], Valid Accuracy: 97.9200, Valid Loss: 0.1501\n",
      "Epoch [1/20], Loss: 2.3016\n",
      "Epoch [1/20], Valid Accuracy: 4.6600, Valid Loss: 2.3538\n",
      "Epoch [2/20], Loss: 0.1774\n",
      "Epoch [2/20], Valid Accuracy: 96.7500, Valid Loss: 0.0992\n",
      "Epoch [3/20], Loss: 0.0803\n",
      "Epoch [3/20], Valid Accuracy: 97.3900, Valid Loss: 0.0870\n",
      "Epoch [4/20], Loss: 0.0553\n",
      "Epoch [4/20], Valid Accuracy: 97.6600, Valid Loss: 0.0774\n",
      "Epoch [5/20], Loss: 0.0443\n",
      "Epoch [5/20], Valid Accuracy: 97.4100, Valid Loss: 0.0903\n",
      "Epoch [6/20], Loss: 0.0334\n",
      "Epoch [6/20], Valid Accuracy: 97.6200, Valid Loss: 0.0875\n",
      "Epoch [7/20], Loss: 0.0283\n",
      "Epoch [7/20], Valid Accuracy: 97.8300, Valid Loss: 0.0860\n",
      "Epoch [8/20], Loss: 0.0242\n",
      "Epoch [8/20], Valid Accuracy: 97.8100, Valid Loss: 0.0850\n",
      "Epoch [9/20], Loss: 0.0226\n",
      "Epoch [9/20], Valid Accuracy: 97.8000, Valid Loss: 0.1016\n",
      "Epoch [10/20], Loss: 0.0188\n",
      "Epoch [10/20], Valid Accuracy: 97.5400, Valid Loss: 0.1088\n",
      "Epoch [11/20], Loss: 0.0192\n",
      "Epoch [11/20], Valid Accuracy: 97.9800, Valid Loss: 0.1023\n",
      "Epoch [12/20], Loss: 0.0159\n",
      "Epoch [12/20], Valid Accuracy: 97.7800, Valid Loss: 0.1180\n",
      "Epoch [13/20], Loss: 0.0161\n",
      "Epoch [13/20], Valid Accuracy: 97.5400, Valid Loss: 0.1258\n",
      "Epoch [14/20], Loss: 0.0135\n",
      "Epoch [14/20], Valid Accuracy: 97.6300, Valid Loss: 0.1251\n",
      "Epoch [15/20], Loss: 0.0149\n",
      "Epoch [15/20], Valid Accuracy: 97.6800, Valid Loss: 0.1370\n",
      "Epoch [16/20], Loss: 0.0133\n",
      "Epoch [16/20], Valid Accuracy: 97.9500, Valid Loss: 0.1160\n",
      "Epoch [17/20], Loss: 0.0117\n",
      "Epoch [17/20], Valid Accuracy: 97.6200, Valid Loss: 0.1480\n",
      "Epoch [18/20], Loss: 0.0123\n",
      "Epoch [18/20], Valid Accuracy: 97.8900, Valid Loss: 0.1347\n",
      "Epoch [19/20], Loss: 0.0123\n",
      "Epoch [19/20], Valid Accuracy: 97.8100, Valid Loss: 0.1309\n",
      "Epoch [20/20], Loss: 0.0136\n",
      "Epoch [20/20], Valid Accuracy: 97.8400, Valid Loss: 0.1466\n"
     ]
    }
   ],
   "source": [
    "dos = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "accs_dos = []\n",
    "train_losses_dos = []\n",
    "val_losses_dos = []\n",
    "for i in dos:\n",
    "    net = get_model_v2(M = 300, p=i)\n",
    "    if i <= 10: \n",
    "        learning_rate = 0.001\n",
    "    else:\n",
    "        learning_rate = 0.0002\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    accs_dos.append(val_acc)\n",
    "    train_losses_dos.append(train_loss)\n",
    "    val_losses_dos.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>train loss</th>\n",
       "      <th>validation loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.76</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.159660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>97.69</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.166253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>98.16</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.149909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>97.79</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.153156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.92</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.150092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>97.84</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.146572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dropout  Val Accuracy  train loss  validation loss\n",
       "0      0.0         97.76    0.012641         0.159660\n",
       "1      0.2         97.69    0.016129         0.166253\n",
       "2      0.4         98.16    0.015384         0.149909\n",
       "3      0.6         97.79    0.009809         0.153156\n",
       "4      0.8         97.92    0.014509         0.150092\n",
       "5      1.0         97.84    0.013618         0.146572"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'Dropout': dos, 'Val Accuracy': accs_dos, 'train loss': train_losses_dos, 'validation loss': val_losses_dos})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In terms of validation accuracy, dropout = 0.4 achieved the best performance. The dropout does help to increase testing accuracy compared to the model without dropout, and this accuracy is better than that of L2 regularization. It is because dropout helps prevent overfitting, thus increases the predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
